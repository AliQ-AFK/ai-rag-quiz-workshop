{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c107c1db-f471-4ccc-8fad-e6fbe08d0eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment variables from /Users/jean.machado@getyourguide.com/prj/rag-workshop/.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean.machado@getyourguide.com/prj/rag-workshop/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading database from /tmp/embedding_db.pkl\n",
      "Created 6 chunks of size 700 with overlap 200\n",
      "Database saved to /tmp/embedding_db.pkl\n",
      "Database saved successfully\n",
      "['What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding']\n"
     ]
    }
   ],
   "source": [
    "from chat_solution.create_db import create_db\n",
    "\n",
    "db = create_db()\n",
    "print(db.retrieve(\"what is a llm?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0362f7-abc1-4043-9ba8-a3648696e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading database from /tmp/embedding_db.pkl\n",
      "Found 5 documents, first 500 characters: ['e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding', 'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding', 'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding', 'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding', 'rs to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embeddings of prompts rather than the prompt text itself to improve model output. It is \\n\\nWhat is Fine-tunning?\\nTBD\\n\\n What are multimodal models? \\nMultimodal models can process and integrate multiple types of data, such as text, images, and audio, to create richer and more comprehensive outputs across different input types.\\n\\nEvaluation\\nEvaluation in LLMs measures model performance using metrics such as accuracy, relevance, and coherence, assessing how well the model fulfills its intended purpose and meet']\n",
      "Result: Based on the provided context, an hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\n"
     ]
    }
   ],
   "source": [
    "# User input and response handling\n",
    "from chat_solution.rag import QuizRag\n",
    "\n",
    "query2 = \"what is an hallucination?\"\n",
    "rag = QuizRag()  \n",
    "response = rag.query(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c60285d-241a-4027-b7f2-3f27a58e5e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 chunks of size 700 with overlap 200\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Convert each text chunk to a LangChain Document\n",
    "from langchain.schema import Document\n",
    "from chat_solution.create_db import create_text_chunks_from_workshop_data\n",
    "\n",
    "text_chunks = create_text_chunks_from_workshop_data()\n",
    "# add all the content chunks to a list of LangChain Documents\n",
    "langchain_docs = [\n",
    "    Document(page_content=text, metadata={\"source\": f\"chunk_{i+1}\"})\n",
    "    for i, text in enumerate(text_chunks)\n",
    "]\n",
    "\n",
    "print(len(langchain_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0000fbcc-8f12-4e14-bc70-642937d55ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatMistralAI(model=\"mistral-large-latest\"))\n",
    "metrics = [LLMContextRecall(), FactualCorrectness(), Faithfulness()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75feb97b-598c-4a2a-aab5-e4fd91b96a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatMistralAI(model=\"mistral-large-latest\"))\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c1a3fc0-7d01-4dc7-b340-f9b3c6b63fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 documents, first 500 characters: ['What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding']\n",
      "Result: A Large Language Model (LLM) is trained on massive datasets of text to predict and generate language based on given prompts. It learns patterns, structures, and relationships in text to produce human-like responses.\n",
      "Found 5 documents, first 500 characters: [' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport', ' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport', ' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport', ' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport', 'model outputs over time.\\n\\nExamples of applying Gen AI\\nGenerative AI can be used for tasks like customer service automation, content creation, coding assistance, personalized marketing, and even medical data analysis, driving efficiency and innovation across industries.\\n\\n\\nEthical considerations\\nEthical issues in AI include data privacy, fairness, transparency, accountability, and the prevention of biases or harmful outputs, necessitating careful oversight and responsible model design.\\n\\n\\n\\n\\nWho are important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research']\n",
      "Error happended while calling the model: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Rate limit error: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Waiting 2 seconds before retrying\n",
      "Result: Based on the provided context, the important role models in the field of AI & ML are:\n",
      "\n",
      "1. **Chip Huyen**: Known for writing a cool blog about ML and AI.\n",
      "2. **Timnit Gebru**: An AI scientist who has many influential papers on AI ethics.\n",
      "3. **Andrej Karpathy**: A research scientist with various influential roles in OpenAI, Tesla, and more, known for keeping a very cool YouTube channel explaining the fundamentals of large language models.\n",
      "Found 5 documents, first 500 characters: ['e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding', 'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding', 'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding', 'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding', 'rs to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embeddings of prompts rather than the prompt text itself to improve model output. It is \\n\\nWhat is Fine-tunning?\\nTBD\\n\\n What are multimodal models? \\nMultimodal models can process and integrate multiple types of data, such as text, images, and audio, to create richer and more comprehensive outputs across different input types.\\n\\nEvaluation\\nEvaluation in LLMs measures model performance using metrics such as accuracy, relevance, and coherence, assessing how well the model fulfills its intended purpose and meet']\n",
      "Result: Based on the context provided:\n",
      "\n",
      "A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\n"
     ]
    }
   ],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "data = [\n",
    "    {'user_input': 'what is a llm?',\n",
    "     'reference': 'A large language model is a type of artificial intelligence model that is designed to understand and generate human language. These models are trained on vast amounts of text data and are capable of generating coherent and contextually appropriate responses to a wide range of questions.',\n",
    "     'reference_contexts': ['A large language model is a type of artificial intelligence model that is designed to understand and generate human language. These models are trained on vast amounts of text data and are capable of generating coherent and contextually appropriate responses to a wide range of questions.']\n",
    "     },\n",
    "     {'user_input': 'how are some role models people the area of artificial intelligence?',\n",
    "      'reference': 'Andrej Karpathy, a well-known figure in the field of artificial intelligence, is a role model for many people in the area. He is known for his work on deep learning and his contributions to the field of AI through his research and development of neural networks and deep learning algorithms.',\n",
    "      'reference_contexts': ['Andrej Karpathy, a well-known figure in the field of artificial intelligence, is a role model for many people in the area. He is known for his work on deep learning and his contributions to the field of AI through his research and development of neural networks and deep learning algorithms.']\n",
    "     },\n",
    "     {'user_input': \"what is an hallucination?\",\n",
    "      'reference': \"An hallucination is a false perception or sensation that occurs in the absence of a corresponding external stimulus. It is often associated with mental health conditions such as schizophrenia or hallucinogenic substances.\",\n",
    "      'reference_contexts': [\"An hallucination is a false perception or sensation that occurs in the absence of a corresponding external stimulus. It is often associated with mental health conditions such as schizophrenia or hallucinogenic substances.\"]\n",
    "      }\n",
    "]\n",
    "\n",
    "\n",
    "# augment data with the llm response\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    response = rag.query(d['user_input'])\n",
    "    data[i]['response'] = response\n",
    "    data[i]['retrieved_contexts'] = rag.documents_retrieved\n",
    "\n",
    "\n",
    "dataset = EvaluationDataset.from_list(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd9007de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_input': 'what is a llm?',\n",
       "  'reference': 'A large language model is a type of artificial intelligence model that is designed to understand and generate human language. These models are trained on vast amounts of text data and are capable of generating coherent and contextually appropriate responses to a wide range of questions.',\n",
       "  'reference_contexts': ['A large language model is a type of artificial intelligence model that is designed to understand and generate human language. These models are trained on vast amounts of text data and are capable of generating coherent and contextually appropriate responses to a wide range of questions.'],\n",
       "  'response': 'A Large Language Model (LLM) is trained on massive datasets of text to predict and generate language based on given prompts. It learns patterns, structures, and relationships in text to produce human-like responses.',\n",
       "  'retrieved_contexts': ['What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr',\n",
       "   'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr',\n",
       "   'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr',\n",
       "   'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr',\n",
       "   'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding']},\n",
       " {'user_input': 'how are some role models people the area of artificial intelligence?',\n",
       "  'reference': 'Andrej Karpathy, a well-known figure in the field of artificial intelligence, is a role model for many people in the area. He is known for his work on deep learning and his contributions to the field of AI through his research and development of neural networks and deep learning algorithms.',\n",
       "  'reference_contexts': ['Andrej Karpathy, a well-known figure in the field of artificial intelligence, is a role model for many people in the area. He is known for his work on deep learning and his contributions to the field of AI through his research and development of neural networks and deep learning algorithms.'],\n",
       "  'response': 'Based on the provided context, the important role models in the field of AI & ML are:\\n\\n1. **Chip Huyen**: Known for writing a cool blog about ML and AI.\\n2. **Timnit Gebru**: An AI scientist who has many influential papers on AI ethics.\\n3. **Andrej Karpathy**: A research scientist with various influential roles in OpenAI, Tesla, and more, known for keeping a very cool YouTube channel explaining the fundamentals of large language models.',\n",
       "  'retrieved_contexts': [' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport',\n",
       "   ' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport',\n",
       "   ' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport',\n",
       "   ' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport',\n",
       "   'model outputs over time.\\n\\nExamples of applying Gen AI\\nGenerative AI can be used for tasks like customer service automation, content creation, coding assistance, personalized marketing, and even medical data analysis, driving efficiency and innovation across industries.\\n\\n\\nEthical considerations\\nEthical issues in AI include data privacy, fairness, transparency, accountability, and the prevention of biases or harmful outputs, necessitating careful oversight and responsible model design.\\n\\n\\n\\n\\nWho are important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research']},\n",
       " {'user_input': 'what is an hallucination?',\n",
       "  'reference': 'An hallucination is a false perception or sensation that occurs in the absence of a corresponding external stimulus. It is often associated with mental health conditions such as schizophrenia or hallucinogenic substances.',\n",
       "  'reference_contexts': ['An hallucination is a false perception or sensation that occurs in the absence of a corresponding external stimulus. It is often associated with mental health conditions such as schizophrenia or hallucinogenic substances.'],\n",
       "  'response': 'Based on the context provided:\\n\\nA hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.',\n",
       "  'retrieved_contexts': ['e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding',\n",
       "   'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding',\n",
       "   'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding',\n",
       "   'e LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\\n\\n\\n\\nWhat is RAG?\\n\\nRetrieval-Augmented Generation (RAG) combines language generation with real-time data retrieval, allowing models to access external sources or databases to provide more accurate, contextually relevant answers.\\n\\n\\nWhat is a hallucination?\\n A hallucination in AI refers to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embedding',\n",
       "   'rs to when a model generates information that sounds plausible but is factually incorrect or unsupported by the training data.\\n\\n\\n\\nPrompt engineering\\nPrompt Tuning: Technique of adjusting the embeddings of prompts rather than the prompt text itself to improve model output. It is \\n\\nWhat is Fine-tunning?\\nTBD\\n\\n What are multimodal models? \\nMultimodal models can process and integrate multiple types of data, such as text, images, and audio, to create richer and more comprehensive outputs across different input types.\\n\\nEvaluation\\nEvaluation in LLMs measures model performance using metrics such as accuracy, relevance, and coherence, assessing how well the model fulfills its intended purpose and meet']}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cbfefec-a59a-4a29-9cd9-d6372dbe1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import LLMContextPrecisionWithReference\n",
    "from ragas.metrics import NonLLMContextRecall\n",
    "from ragas.metrics import LLMContextRecall\n",
    "from ragas.metrics import Faithfulness\n",
    "from ragas.metrics import ResponseRelevancy\n",
    "from ragas import evaluate\n",
    "\n",
    "faithfulness = Faithfulness()\n",
    "context_precision = LLMContextPrecisionWithReference()\n",
    "context_recall = NonLLMContextRecall()\n",
    "llm_context_recall = LLMContextRecall()\n",
    "answer_relevancy = ResponseRelevancy()\n",
    "\n",
    "eval_results = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[\n",
    "                faithfulness,\n",
    "                answer_relevancy,\n",
    "                context_precision,\n",
    "                context_recall,\n",
    "                llm_context_recall\n",
    "        ],\n",
    "       raise_exceptions=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c140c6-443b-4e1f-919e-afb9954d6a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>llm_context_precision_with_reference</th>\n",
       "      <th>non_llm_context_recall</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is a llm?</td>\n",
       "      <td>[What are LLMs?\\n\\nLarge Language Models (LLMs...</td>\n",
       "      <td>[A large language model is a type of artificia...</td>\n",
       "      <td>A Large Language Model (LLM) is trained on mas...</td>\n",
       "      <td>A large language model is a type of artificial...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how are some role models people the area of ar...</td>\n",
       "      <td>[ important role models in the field of AI &amp; M...</td>\n",
       "      <td>[Andrej Karpathy, a well-known figure in the f...</td>\n",
       "      <td>Based on the provided context, the important r...</td>\n",
       "      <td>Andrej Karpathy, a well-known figure in the fi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.927337</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is an hallucination?</td>\n",
       "      <td>[e LLMs are proprietary, with code and models ...</td>\n",
       "      <td>[An hallucination is a false perception or sen...</td>\n",
       "      <td>Based on the context provided:\\n\\nA hallucinat...</td>\n",
       "      <td>An hallucination is a false perception or sens...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0                                     what is a llm?   \n",
       "1  how are some role models people the area of ar...   \n",
       "2                          what is an hallucination?   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [What are LLMs?\\n\\nLarge Language Models (LLMs...   \n",
       "1  [ important role models in the field of AI & M...   \n",
       "2  [e LLMs are proprietary, with code and models ...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [A large language model is a type of artificia...   \n",
       "1  [Andrej Karpathy, a well-known figure in the f...   \n",
       "2  [An hallucination is a false perception or sen...   \n",
       "\n",
       "                                            response  \\\n",
       "0  A Large Language Model (LLM) is trained on mas...   \n",
       "1  Based on the provided context, the important r...   \n",
       "2  Based on the context provided:\\n\\nA hallucinat...   \n",
       "\n",
       "                                           reference  faithfulness  \\\n",
       "0  A large language model is a type of artificial...           1.0   \n",
       "1  Andrej Karpathy, a well-known figure in the fi...           1.0   \n",
       "2  An hallucination is a false perception or sens...           1.0   \n",
       "\n",
       "   answer_relevancy  llm_context_precision_with_reference  \\\n",
       "0          0.836305                                   1.0   \n",
       "1          0.927337                                   1.0   \n",
       "2          0.899427                                   0.0   \n",
       "\n",
       "   non_llm_context_recall  context_recall  \n",
       "0                     0.0             1.0  \n",
       "1                     0.0             0.5  \n",
       "2                     0.0             0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_result_df = eval_results.to_pandas()\n",
    "evaluation_result_df.iloc[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
