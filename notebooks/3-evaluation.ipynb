{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107c1db-f471-4ccc-8fad-e6fbe08d0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat_solution.create_db import create_db\n",
    "\n",
    "db = create_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27daf9d1-34ee-4a79-9af5-b556aadc6958",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.retrieve(\"How do you pick a green?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0362f7-abc1-4043-9ba8-a3648696e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input and response handling\n",
    "from chat_solution.rag import QuizRag\n",
    "\n",
    "query1 = \"what is up?\"\n",
    "query2 = \"How do you pick a green?\"\n",
    "rag = QuizRag()  \n",
    "response = rag.query(query2)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c60285d-241a-4027-b7f2-3f27a58e5e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 chunks of size 700 with overlap 200\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Convert each text chunk to a LangChain Document\n",
    "from langchain.schema import Document\n",
    "from chat_solution.create_db import create_text_chunks_from_workshop_data\n",
    "\n",
    "text_chunks = create_text_chunks_from_workshop_data()\n",
    "# add all the content chunks to a list of LangChain Documents\n",
    "langchain_docs = [\n",
    "    Document(page_content=text, metadata={\"source\": f\"chunk_{i+1}\"})\n",
    "    for i, text in enumerate(text_chunks)\n",
    "]\n",
    "\n",
    "print(len(langchain_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0000fbcc-8f12-4e14-bc70-642937d55ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatMistralAI(model=\"mistral-large-latest\"))\n",
    "metrics = [LLMContextRecall(), FactualCorrectness(), Faithfulness()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75feb97b-598c-4a2a-aab5-e4fd91b96a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatMistralAI(model=\"mistral-large-latest\"))\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c1a3fc0-7d01-4dc7-b340-f9b3c6b63fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  25%|██▌       | 3/12 [00:28<01:03,  7.10s/it]Property 'themes' already exists in node '2b5dc9'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  42%|████▏     | 5/12 [00:37<00:35,  5.02s/it]Property 'themes' already exists in node 'fd4011'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  58%|█████▊    | 7/12 [00:55<00:37,  7.44s/it]Property 'themes' already exists in node 'cbb6db'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  75%|███████▌  | 9/12 [01:13<00:27,  9.02s/it]Property 'themes' already exists in node '8ae330'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  83%|████████▎ | 10/12 [01:18<00:15,  7.77s/it]Property 'themes' already exists in node '9ecbc5'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  92%|█████████▏| 11/12 [01:20<00:06,  6.14s/it]Property 'themes' already exists in node 'ced5e0'. Skipping!\n",
      "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]               unable to apply transformation: axis 1 is out of bounds for array of dimension 1\n",
      "                                                                                              \r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtestset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TestsetGenerator\n\u001b[1;32m      3\u001b[0m generator \u001b[38;5;241m=\u001b[39m TestsetGenerator(llm\u001b[38;5;241m=\u001b[39mgenerator_llm)\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlangchain_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtransforms_embedding_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prj/rag-workshop/.venv/lib/python3.12/site-packages/ragas/testset/synthesizers/generate.py:180\u001b[0m, in \u001b[0;36mTestsetGenerator.generate_with_langchain_docs\u001b[0;34m(self, documents, testset_size, transforms, transforms_llm, transforms_embedding_model, query_distribution, run_config, callbacks, with_debugging_logs, raise_exceptions)\u001b[0m\n\u001b[1;32m    177\u001b[0m apply_transforms(kg, transforms)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknowledge_graph \u001b[38;5;241m=\u001b[39m kg\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prj/rag-workshop/.venv/lib/python3.12/site-packages/ragas/testset/synthesizers/generate.py:352\u001b[0m, in \u001b[0;36mTestsetGenerator.generate\u001b[0;34m(self, testset_size, query_distribution, num_personas, run_config, batch_size, callbacks, token_usage_parser, with_debugging_logs, raise_exceptions)\u001b[0m\n\u001b[1;32m    349\u001b[0m     patch_logger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mragas.experimental.testset.transforms\u001b[39m\u001b[38;5;124m\"\u001b[39m, logging\u001b[38;5;241m.\u001b[39mDEBUG)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersona_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersona_list \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_personas_from_kg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknowledge_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_personas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_personas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     random\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersona_list)\n",
      "File \u001b[0;32m~/prj/rag-workshop/.venv/lib/python3.12/site-packages/ragas/testset/persona.py:127\u001b[0m, in \u001b[0;36mgenerate_personas_from_kg\u001b[0;34m(kg, llm, persona_generation_prompt, num_personas, filter_fn, callbacks)\u001b[0m\n\u001b[1;32m    123\u001b[0m     top_summaries\u001b[38;5;241m.\u001b[39mappend(representative_summary)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(top_summaries) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m num_personas:\n\u001b[1;32m    126\u001b[0m     top_summaries\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 127\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_summaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_personas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtop_summaries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     )\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# use run_async_batch to generate personas in parallel\u001b[39;00m\n\u001b[1;32m    131\u001b[0m kwargs_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    132\u001b[0m     {\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m: llm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m summary \u001b[38;5;129;01min\u001b[39;00m top_summaries[:num_personas]\n\u001b[1;32m    139\u001b[0m ]\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:951\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm)\n",
    "dataset = generator.generate_with_langchain_docs(langchain_docs,transforms_embedding_model=generator_embeddings, testset_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1856cab-65a9-4212-95d5-a42725294ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepared questions dataset from huggingface\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"atitaarora/food_lab_green_qna\", split=\"train\")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ee129-023b-4942-bb7d-8717baf88432",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample question data\n",
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca66ec5-6486-4956-a361-5b0fed11145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ragas import evaluate\n",
    "#results = evaluate(dataset=dataset, metrics=metrics, llm=evaluator_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0cfa60f6-ee2d-4cc8-821c-07b7fddd745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparation of Eval dataset for RAGAS (https://docs.ragas.io/en/stable/concepts/components/eval_sample/?h=singleturnsample#example)\n",
    "##for ragas dataset needs to be in the designated format \n",
    "from ragas import EvaluationDataset, SingleTurnSample\n",
    "from ragas.metrics import Faithfulness\n",
    "from datasets import load_dataset\n",
    "from ragas import evaluate\n",
    "import time\n",
    "\n",
    "samples = []\n",
    "eval_size = 5\n",
    "\n",
    "for i in range(eval_size):\n",
    "    entry = dataset[i]\n",
    "    \n",
    "    # Perform the query with a delay to limit to 1 request per second\n",
    "    user_query = entry['query']\n",
    "    response = rag.query(user_query)\n",
    "    \n",
    "    sample = SingleTurnSample(\n",
    "        user_input=user_query,\n",
    "        reference=entry['reference_answer'],\n",
    "        response=response,\n",
    "        retrieved_contexts=db.retrieve(user_query),\n",
    "    )\n",
    "    samples.append(sample)\n",
    "    \n",
    "    # Wait for 1-2 second before proceeding to the next iteration as we are limited by Mistral API\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5fadb-0058-4a87-9b13-bdbf23e5b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(samples)\n",
    "\n",
    "# Display the DataFrame as a table\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbfefec-a59a-4a29-9cd9-d6372dbe1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actual Evaluation\n",
    "from ragas.metrics import LLMContextPrecisionWithReference\n",
    "from ragas.metrics import NonLLMContextRecall\n",
    "from ragas.metrics import LLMContextRecall\n",
    "from ragas.metrics import Faithfulness\n",
    "from ragas.metrics import ResponseRelevancy\n",
    "\n",
    "eval_dataset = EvaluationDataset(samples=samples)\n",
    "\n",
    "faithfulness = Faithfulness()\n",
    "context_precision = LLMContextPrecisionWithReference()\n",
    "context_recall = NonLLMContextRecall()\n",
    "llm_context_recall = LLMContextRecall()\n",
    "answer_relevancy = ResponseRelevancy()\n",
    "\n",
    "eval_results = evaluate(\n",
    "        dataset=eval_dataset,\n",
    "        metrics=[\n",
    "                faithfulness,\n",
    "                answer_relevancy,\n",
    "                #context_recall, #This metric [non_llm_context_recall] that is used requires the following additional columns ['reference_contexts'] to be present in the dataset.\n",
    "                llm_context_recall,\n",
    "                context_precision,\n",
    "        ],\n",
    "       #llm=evaluator_llm\n",
    "       raise_exceptions=False \n",
    "    )\n",
    "#eval_results = evaluate(\n",
    "#    dataset=eval_dataset,\n",
    "#    metrics=[metric],\n",
    "#llm=evaluator_llm\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c140c6-443b-4e1f-919e-afb9954d6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result_df = eval_results.to_pandas()\n",
    "evaluation_result_df.iloc[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
