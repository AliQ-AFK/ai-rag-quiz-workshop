{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e824fd",
   "metadata": {},
   "source": [
    "\n",
    "## Building applications and evaluating their performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4fc601",
   "metadata": {},
   "source": [
    "Now lets jump to our application. The purpose of this part is to give you an overview of everything you need to do to get an chat-application working.\n",
    "\n",
    "The folder chat_solution contains the app. Lets try to initialize it and try it out.\n",
    "\n",
    "For our chat we will use data available in the daata folder.\n",
    "Our first step is to load this data inside the LLM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c107c1db-f471-4ccc-8fad-e6fbe08d0eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment variables from /Users/jean.machado@getyourguide.com/prj/rag-workshop/.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean.machado@getyourguide.com/prj/rag-workshop/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading database from /tmp/embedding_db.pkl\n",
      "Created 6 chunks of size 700 with overlap 200\n",
      "Database saved to /tmp/embedding_db.pkl\n",
      "Database saved successfully\n",
      "['What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr']\n"
     ]
    }
   ],
   "source": [
    "from chat_solution.create_db import create_db\n",
    "\n",
    "db = create_db()\n",
    "print(db.retrieve(\"what is a llm?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088798a1",
   "metadata": {},
   "source": [
    "## Creating our rag script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0362f7-abc1-4043-9ba8-a3648696e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading database from /tmp/embedding_db.pkl\n",
      "Quis assistant initialized\n",
      "[]\n",
      " You are a helpful AI knowledge quiz chat assistant. Your goal is to test the knowledge of the users on the given topic.\"\n",
      "The user gives you a topic or a question and you should generate a new relevant quiz based on the context.\n",
      "- Generate a new relevant quiz question based on the context and the topic provided. The topic you select on the context does not need to be exactly the same, but should be related to the topic.\n",
      "- Your primary audience are students learning about AI. Do not use technical jargon that is not common knowledge or that you dont explain first.\n",
      "- The question should be relevant to the given topic and the answer should be found within the given context. If not say: \"You did not equip me with the knowledge to answer this question.\"\n",
      "- Provide 4 answer choices for the question, one of which should be correct and the other three should be incorrect but plausible. Answer choices should be formulated clearly and concisely.\n",
      "- Mark the index of the correct answer in the answer choices list with the pattern (CORRECT) in the end\n",
      "if the user answers with a number, it is because they selected an answer to the previous question. In this case, you should evaluate if the answer is correct or not and provide feedback to the user.\n",
      "- Do not mention the context in your response.\n",
      "- Provide an explanation for previous question after the user selected an answer. The explanation should give the user additional context and help them better understand the topic.\n",
      "- Do not generate questions that are not about AI or ML.\n",
      "\n",
      "<startexample>\n",
      "Interaction 1\n",
      "New Context: LLMs are large language models that can generate responses to user queries. They are trained on massive datasets to learn patterns, structures, and relationships in text. They can generate responses by combining language generation with real-time data retrieval.\n",
      "User input: How do LLMs generate responses?\n",
      "Assistant:\n",
      "Question: How do LLMs generate responses?\n",
      "1. LLMs generate responses by searching the internet for relevant information. \n",
      "2. LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets. (CORRECT)\n",
      "3. LLMs generate responses by combining language generation with real-time data retrieval.\n",
      "4. LMs generate responses by using a predefined set of rules and templates.\n",
      "Interaction 2\n",
      "User input: 3\n",
      "Assistant:Incorrect! LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets.\n",
      "Interaction 3\n",
      "User input: 2\n",
      "Assistant:Correct! LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets.\n",
      "</endexample>\n",
      "\n",
      "Now we start the conversation history:\n",
      "\n",
      "\n",
      "Just predict the next answer:\n",
      "Interaction 2 \n",
      "New Context: ['cination in AI refers to when a model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data.\\n\\nUnderstanding hallucinations in AI\\nCharacteristics:\\nInaccuracy: The generated text may contain false statements or incorrect information.\\nIrrelevance: The response might include details that are not relevant to the input or context.\\nInvented Content: The model may create entirely fabricated details or scenarios that do not exist.\\n\\nMitigating Hallucinations\\nImproving training data: Ensuring that the training data is comprehensive, accurate, and representative of real-world knowledge can help reduce hallucinations.\\nFine-tuning: Fine-tun', 'cination in AI refers to when a model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data.\\n\\nUnderstanding hallucinations in AI\\nCharacteristics:\\nInaccuracy: The generated text may contain false statements or incorrect information.\\nIrrelevance: The response might include details that are not relevant to the input or context.\\nInvented Content: The model may create entirely fabricated details or scenarios that do not exist.\\n\\nMitigating Hallucinations\\nImproving training data: Ensuring that the training data is comprehensive, accurate, and representative of real-world knowledge can help reduce hallucinations.\\nFine-tuning: Fine-tun', 'cination in AI refers to when a model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data.\\n\\nUnderstanding hallucinations in AI\\nCharacteristics:\\nInaccuracy: The generated text may contain false statements or incorrect information.\\nIrrelevance: The response might include details that are not relevant to the input or context.\\nInvented Content: The model may create entirely fabricated details or scenarios that do not exist.\\n\\nMitigating Hallucinations\\nImproving training data: Ensuring that the training data is comprehensive, accurate, and representative of real-world knowledge can help reduce hallucinations.\\nFine-tuning: Fine-tun', 'cination in AI refers to when a model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data.\\n\\nUnderstanding hallucinations in AI\\nCharacteristics:\\nInaccuracy: The generated text may contain false statements or incorrect information.\\nIrrelevance: The response might include details that are not relevant to the input or context.\\nInvented Content: The model may create entirely fabricated details or scenarios that do not exist.\\n\\nMitigating Hallucinations\\nImproving training data: Ensuring that the training data is comprehensive, accurate, and representative of real-world knowledge can help reduce hallucinations.\\nFine-tuning: Fine-tun', 'cination in AI refers to when a model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data.\\n\\nUnderstanding hallucinations in AI\\nCharacteristics:\\nInaccuracy: The generated text may contain false statements or incorrect information.\\nIrrelevance: The response might include details that are not relevant to the input or context.\\nInvented Content: The model may create entirely fabricated details or scenarios that do not exist.\\n\\nMitigating Hallucinations\\nImproving training data: Ensuring that the training data is comprehensive, accurate, and representative of real-world knowledge can help reduce hallucinations.\\nFine-tuning: Fine-tun']\n",
      "User input: what is an hallucination?\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "# User input and response handling\n",
    "from chat_solution.rag import LearningAssistant\n",
    "\n",
    "query2 = \"what is an hallucination?\"\n",
    "rag = LearningAssistant()  \n",
    "response = rag.query(query2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7865ae7c",
   "metadata": {},
   "source": [
    "\n",
    "## Running our chat application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a510adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8503\n",
      "  Network URL: http://192.168.178.64:8503\n",
      "\n",
      "Loading environment variables from /Users/jean.machado@getyourguide.com/prj/rag-workshop/.env\n",
      "Loading database from /tmp/embedding_db.pkl\n",
      "Quis assistant initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 15:40:03.762 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      " You are a helpful AI knowledge quiz chat assistant. Your goal is to test the knowledge of the users on the given topic.\"\n",
      "The user gives you a topic or a question and you should generate a new relevant quiz based on the context.\n",
      "- Generate a new relevant quiz question based on the context and the topic provided. The topic you select on the context does not need to be exactly the same, but should be related to the topic.\n",
      "- Your primary audience are students learning about AI. Do not use technical jargon that is not common knowledge or that you dont explain first.\n",
      "- The question should be relevant to the given topic and the answer should be found within the given context. If not say: \"You did not equip me with the knowledge to answer this question.\"\n",
      "- Provide 4 answer choices for the question, one of which should be correct and the other three should be incorrect but plausible. Answer choices should be formulated clearly and concisely.\n",
      "- Mark the index of the correct answer in the answer choices list with the pattern (CORRECT) in the end\n",
      "if the user answers with a number, it is because they selected an answer to the previous question. In this case, you should evaluate if the answer is correct or not and provide feedback to the user.\n",
      "- Do not mention the context in your response.\n",
      "- Provide an explanation for previous question after the user selected an answer. The explanation should give the user additional context and help them better understand the topic.\n",
      "- Do not generate questions that are not about AI or ML.\n",
      "\n",
      "<startexample>\n",
      "Interaction 1\n",
      "New Context: LLMs are large language models that can generate responses to user queries. They are trained on massive datasets to learn patterns, structures, and relationships in text. They can generate responses by combining language generation with real-time data retrieval.\n",
      "User input: How do LLMs generate responses?\n",
      "Assistant:\n",
      "Question: How do LLMs generate responses?\n",
      "1. LLMs generate responses by searching the internet for relevant information. \n",
      "2. LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets. (CORRECT)\n",
      "3. LLMs generate responses by combining language generation with real-time data retrieval.\n",
      "4. LMs generate responses by using a predefined set of rules and templates.\n",
      "Interaction 2\n",
      "User input: 3\n",
      "Assistant:Incorrect! LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets.\n",
      "Interaction 3\n",
      "User input: 2\n",
      "Assistant:Correct! LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets.\n",
      "</endexample>\n",
      "\n",
      "Now we start the conversation history:\n",
      "\n",
      "\n",
      "Just predict the next answer:\n",
      "Interaction 2 \n",
      "New Context: ['et of natural language understanding tasks.\\nSuperGLUE: An advanced version of GLUE, designed to be more challenging and to push the boundaries of what LLMs can achieve in natural language understanding.\\nCoQA (Conversational Question Answering): A benchmark for evaluating the ability of LLMs to understand and generate responses in a conversational context.\\nBy using these benchmarks, researchers can systematically assess the performance of LLMs, ensuring that comparisons are consistent and meaningful. This process helps in identifying areas where models excel and where they need improvement, guiding future development and optimization efforts.\\n\\nMonitoring \\n\\nMonitoring involves tracking an LLM’', 'et of natural language understanding tasks.\\nSuperGLUE: An advanced version of GLUE, designed to be more challenging and to push the boundaries of what LLMs can achieve in natural language understanding.\\nCoQA (Conversational Question Answering): A benchmark for evaluating the ability of LLMs to understand and generate responses in a conversational context.\\nBy using these benchmarks, researchers can systematically assess the performance of LLMs, ensuring that comparisons are consistent and meaningful. This process helps in identifying areas where models excel and where they need improvement, guiding future development and optimization efforts.\\n\\nMonitoring \\n\\nMonitoring involves tracking an LLM’', 'et of natural language understanding tasks.\\nSuperGLUE: An advanced version of GLUE, designed to be more challenging and to push the boundaries of what LLMs can achieve in natural language understanding.\\nCoQA (Conversational Question Answering): A benchmark for evaluating the ability of LLMs to understand and generate responses in a conversational context.\\nBy using these benchmarks, researchers can systematically assess the performance of LLMs, ensuring that comparisons are consistent and meaningful. This process helps in identifying areas where models excel and where they need improvement, guiding future development and optimization efforts.\\n\\nMonitoring \\n\\nMonitoring involves tracking an LLM’', 'et of natural language understanding tasks.\\nSuperGLUE: An advanced version of GLUE, designed to be more challenging and to push the boundaries of what LLMs can achieve in natural language understanding.\\nCoQA (Conversational Question Answering): A benchmark for evaluating the ability of LLMs to understand and generate responses in a conversational context.\\nBy using these benchmarks, researchers can systematically assess the performance of LLMs, ensuring that comparisons are consistent and meaningful. This process helps in identifying areas where models excel and where they need improvement, guiding future development and optimization efforts.\\n\\nMonitoring \\n\\nMonitoring involves tracking an LLM’', 'et of natural language understanding tasks.\\nSuperGLUE: An advanced version of GLUE, designed to be more challenging and to push the boundaries of what LLMs can achieve in natural language understanding.\\nCoQA (Conversational Question Answering): A benchmark for evaluating the ability of LLMs to understand and generate responses in a conversational context.\\nBy using these benchmarks, researchers can systematically assess the performance of LLMs, ensuring that comparisons are consistent and meaningful. This process helps in identifying areas where models excel and where they need improvement, guiding future development and optimization efforts.\\n\\nMonitoring \\n\\nMonitoring involves tracking an LLM’']\n",
      "User input: test jean\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"pkill -f stremalit \")\n",
    "os.system(\"streamlit run ../chat_solution/start_streamlit.py &\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2ddc4",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c1a3fc0-7d01-4dc7-b340-f9b3c6b63fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what is an hallucination?', 'Question: What is a hallucination in the context of AI?\\n1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\\n2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\\n3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\\n4. Hallucinations happen only in image-generating AI models, not in language models.'), ('what is a llm?', 'Question: What is a Large Language Model (LLM)?\\n1. An LLM is a type of artificial intelligence that can understand and generate human language. (CORRECT)\\n2. LLMs are primarily used for image processing and analysis.\\n3. LLMs are designed to predict and generate mathematical equations.\\n4. LLMs are used exclusively in robotics for motion control.'), ('how are some role models people the area of artificial intelligence?', 'Question: Who is a notable role model in the field of artificial intelligence?\\n1. Elon Musk: Known for his work in space exploration and electric vehicles.\\n2. Timnit Gebru: An AI scientist with many influential papers on AI ethics. (CORRECT)\\n3. Alan Turing: Known for his work in codebreaking and computer science fundamentals.\\n4. Satya Nadella: CEO of Microsoft, known for his work in cloud computing.'), ('what is an hallucination?', 'Question: What is a hallucination in the context of AI?\\n1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\\n2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\\n3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\\n4. Hallucinations happen only in image-generating AI models, not in language models.')]\n",
      " You are a helpful AI knowledge quiz chat assistant. Your goal is to test the knowledge of the users on the given topic.\"\n",
      "The user gives you a topic or a question and you should generate a new relevant quiz based on the context.\n",
      "- Generate a new relevant quiz question based on the context and the topic provided. The topic you select on the context does not need to be exactly the same, but should be related to the topic.\n",
      "- Your primary audience are students learning about AI. Do not use technical jargon that is not common knowledge or that you dont explain first.\n",
      "- The question should be relevant to the given topic and the answer should be found within the given context. If not say: \"You did not equip me with the knowledge to answer this question.\"\n",
      "- Provide 4 answer choices for the question, one of which should be correct and the other three should be incorrect but plausible. Answer choices should be formulated clearly and concisely.\n",
      "- Mark the index of the correct answer in the answer choices list with the pattern (CORRECT) in the end\n",
      "if the user answers with a number, it is because they selected an answer to the previous question. In this case, you should evaluate if the answer is correct or not and provide feedback to the user.\n",
      "- Do not mention the context in your response.\n",
      "- Provide an explanation for previous question after the user selected an answer. The explanation should give the user additional context and help them better understand the topic.\n",
      "- Do not generate questions that are not about AI or ML.\n",
      "\n",
      "<startexample>\n",
      "Interaction 1\n",
      "New Context: LLMs are large language models that can generate responses to user queries. They are trained on massive datasets to learn patterns, structures, and relationships in text. They can generate responses by combining language generation with real-time data retrieval.\n",
      "User input: How do LLMs generate responses?\n",
      "Assistant:\n",
      "Question: How do LLMs generate responses?\n",
      "1. LLMs generate responses by searching the internet for relevant information. \n",
      "2. LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets. (CORRECT)\n",
      "3. LLMs generate responses by combining language generation with real-time data retrieval.\n",
      "4. LMs generate responses by using a predefined set of rules and templates.\n",
      "Interaction 2\n",
      "User input: 3\n",
      "Assistant:Incorrect! LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets.\n",
      "Interaction 3\n",
      "User input: 2\n",
      "Assistant:Correct! LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets.\n",
      "</endexample>\n",
      "\n",
      "Now we start the conversation history:\n",
      "Interaction 1\n",
      "User: what is an hallucination?\n",
      "Assistant: Question: What is a hallucination in the context of AI?\n",
      "1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\n",
      "2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\n",
      "3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\n",
      "4. Hallucinations happen only in image-generating AI models, not in language models.\n",
      "Interaction 2\n",
      "User: what is a llm?\n",
      "Assistant: Question: What is a Large Language Model (LLM)?\n",
      "1. An LLM is a type of artificial intelligence that can understand and generate human language. (CORRECT)\n",
      "2. LLMs are primarily used for image processing and analysis.\n",
      "3. LLMs are designed to predict and generate mathematical equations.\n",
      "4. LLMs are used exclusively in robotics for motion control.\n",
      "Interaction 3\n",
      "User: how are some role models people the area of artificial intelligence?\n",
      "Assistant: Question: Who is a notable role model in the field of artificial intelligence?\n",
      "1. Elon Musk: Known for his work in space exploration and electric vehicles.\n",
      "2. Timnit Gebru: An AI scientist with many influential papers on AI ethics. (CORRECT)\n",
      "3. Alan Turing: Known for his work in codebreaking and computer science fundamentals.\n",
      "4. Satya Nadella: CEO of Microsoft, known for his work in cloud computing.\n",
      "Interaction 4\n",
      "User: what is an hallucination?\n",
      "Assistant: Question: What is a hallucination in the context of AI?\n",
      "1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\n",
      "2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\n",
      "3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\n",
      "4. Hallucinations happen only in image-generating AI models, not in language models.\n",
      "\n",
      "\n",
      "Just predict the next answer:\n",
      "Interaction 6 \n",
      "New Context: ['What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr']\n",
      "User input: what is a llm?\n",
      "Assistant:\n",
      "[('what is an hallucination?', 'Question: What is a hallucination in the context of AI?\\n1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\\n2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\\n3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\\n4. Hallucinations happen only in image-generating AI models, not in language models.'), ('what is a llm?', 'Question: What is a Large Language Model (LLM)?\\n1. An LLM is a type of artificial intelligence that can understand and generate human language. (CORRECT)\\n2. LLMs are primarily used for image processing and analysis.\\n3. LLMs are designed to predict and generate mathematical equations.\\n4. LLMs are used exclusively in robotics for motion control.'), ('how are some role models people the area of artificial intelligence?', 'Question: Who is a notable role model in the field of artificial intelligence?\\n1. Elon Musk: Known for his work in space exploration and electric vehicles.\\n2. Timnit Gebru: An AI scientist with many influential papers on AI ethics. (CORRECT)\\n3. Alan Turing: Known for his work in codebreaking and computer science fundamentals.\\n4. Satya Nadella: CEO of Microsoft, known for his work in cloud computing.'), ('what is an hallucination?', 'Question: What is a hallucination in the context of AI?\\n1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\\n2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\\n3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\\n4. Hallucinations happen only in image-generating AI models, not in language models.'), ('what is a llm?', 'Question: What is a Large Language Model (LLM)?\\n1. An LLM is a type of artificial intelligence that can understand and generate human language. (CORRECT)\\n2. LLMs are primarily used for image processing and analysis.\\n3. LLMs are designed to predict and generate mathematical equations.\\n4. LLMs are used exclusively in robotics for motion control.')]\n",
      " You are a helpful AI knowledge quiz chat assistant. Your goal is to test the knowledge of the users on the given topic.\"\n",
      "The user gives you a topic or a question and you should generate a new relevant quiz based on the context.\n",
      "- Generate a new relevant quiz question based on the context and the topic provided. The topic you select on the context does not need to be exactly the same, but should be related to the topic.\n",
      "- Your primary audience are students learning about AI. Do not use technical jargon that is not common knowledge or that you dont explain first.\n",
      "- The question should be relevant to the given topic and the answer should be found within the given context. If not say: \"You did not equip me with the knowledge to answer this question.\"\n",
      "- Provide 4 answer choices for the question, one of which should be correct and the other three should be incorrect but plausible. Answer choices should be formulated clearly and concisely.\n",
      "- Mark the index of the correct answer in the answer choices list with the pattern (CORRECT) in the end\n",
      "if the user answers with a number, it is because they selected an answer to the previous question. In this case, you should evaluate if the answer is correct or not and provide feedback to the user.\n",
      "- Do not mention the context in your response.\n",
      "- Provide an explanation for previous question after the user selected an answer. The explanation should give the user additional context and help them better understand the topic.\n",
      "- Do not generate questions that are not about AI or ML.\n",
      "\n",
      "<startexample>\n",
      "Interaction 1\n",
      "New Context: LLMs are large language models that can generate responses to user queries. They are trained on massive datasets to learn patterns, structures, and relationships in text. They can generate responses by combining language generation with real-time data retrieval.\n",
      "User input: How do LLMs generate responses?\n",
      "Assistant:\n",
      "Question: How do LLMs generate responses?\n",
      "1. LLMs generate responses by searching the internet for relevant information. \n",
      "2. LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets. (CORRECT)\n",
      "3. LLMs generate responses by combining language generation with real-time data retrieval.\n",
      "4. LMs generate responses by using a predefined set of rules and templates.\n",
      "Interaction 2\n",
      "User input: 3\n",
      "Assistant:Incorrect! LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets.\n",
      "Interaction 3\n",
      "User input: 2\n",
      "Assistant:Correct! LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets.\n",
      "</endexample>\n",
      "\n",
      "Now we start the conversation history:\n",
      "Interaction 1\n",
      "User: what is an hallucination?\n",
      "Assistant: Question: What is a hallucination in the context of AI?\n",
      "1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\n",
      "2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\n",
      "3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\n",
      "4. Hallucinations happen only in image-generating AI models, not in language models.\n",
      "Interaction 2\n",
      "User: what is a llm?\n",
      "Assistant: Question: What is a Large Language Model (LLM)?\n",
      "1. An LLM is a type of artificial intelligence that can understand and generate human language. (CORRECT)\n",
      "2. LLMs are primarily used for image processing and analysis.\n",
      "3. LLMs are designed to predict and generate mathematical equations.\n",
      "4. LLMs are used exclusively in robotics for motion control.\n",
      "Interaction 3\n",
      "User: how are some role models people the area of artificial intelligence?\n",
      "Assistant: Question: Who is a notable role model in the field of artificial intelligence?\n",
      "1. Elon Musk: Known for his work in space exploration and electric vehicles.\n",
      "2. Timnit Gebru: An AI scientist with many influential papers on AI ethics. (CORRECT)\n",
      "3. Alan Turing: Known for his work in codebreaking and computer science fundamentals.\n",
      "4. Satya Nadella: CEO of Microsoft, known for his work in cloud computing.\n",
      "Interaction 4\n",
      "User: what is an hallucination?\n",
      "Assistant: Question: What is a hallucination in the context of AI?\n",
      "1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\n",
      "2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\n",
      "3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\n",
      "4. Hallucinations happen only in image-generating AI models, not in language models.\n",
      "Interaction 5\n",
      "User: what is a llm?\n",
      "Assistant: Question: What is a Large Language Model (LLM)?\n",
      "1. An LLM is a type of artificial intelligence that can understand and generate human language. (CORRECT)\n",
      "2. LLMs are primarily used for image processing and analysis.\n",
      "3. LLMs are designed to predict and generate mathematical equations.\n",
      "4. LLMs are used exclusively in robotics for motion control.\n",
      "\n",
      "\n",
      "Just predict the next answer:\n",
      "Interaction 7 \n",
      "New Context: [' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport', ' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport', ' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport', ' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport', ' important role models in the field of AI & ML?\\n\\nChip Huyen: Writes  a cool blog  about ML and AI\\nTimnit Gebru: An AI scientist that have many influential papers on AI ethics\\nAndrej Karpathy: Research scientist on various influential roles in OpenAI, tesla, and more, keeps a very cool youtube channel explaining the fundamentals of large language models.\\n\\nEthics quiz\\n\\nYou are an AI developer working at a technology firm called Techscape. In order to make the recruitment process easier, the company has decided to develop an AI-based recruitment tool that automatically shortlists potential candidates based on their CVs. However, after putting it to use, it is discovered that the tool disproport']\n",
      "User input: role models in the area of artificial intelligence?\n",
      "Assistant:\n",
      "[('what is an hallucination?', 'Question: What is a hallucination in the context of AI?\\n1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\\n2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\\n3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\\n4. Hallucinations happen only in image-generating AI models, not in language models.'), ('what is a llm?', 'Question: What is a Large Language Model (LLM)?\\n1. An LLM is a type of artificial intelligence that can understand and generate human language. (CORRECT)\\n2. LLMs are primarily used for image processing and analysis.\\n3. LLMs are designed to predict and generate mathematical equations.\\n4. LLMs are used exclusively in robotics for motion control.'), ('how are some role models people the area of artificial intelligence?', 'Question: Who is a notable role model in the field of artificial intelligence?\\n1. Elon Musk: Known for his work in space exploration and electric vehicles.\\n2. Timnit Gebru: An AI scientist with many influential papers on AI ethics. (CORRECT)\\n3. Alan Turing: Known for his work in codebreaking and computer science fundamentals.\\n4. Satya Nadella: CEO of Microsoft, known for his work in cloud computing.'), ('what is an hallucination?', 'Question: What is a hallucination in the context of AI?\\n1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\\n2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\\n3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\\n4. Hallucinations happen only in image-generating AI models, not in language models.'), ('what is a llm?', 'Question: What is a Large Language Model (LLM)?\\n1. An LLM is a type of artificial intelligence that can understand and generate human language. (CORRECT)\\n2. LLMs are primarily used for image processing and analysis.\\n3. LLMs are designed to predict and generate mathematical equations.\\n4. LLMs are used exclusively in robotics for motion control.'), ('role models in the area of artificial intelligence?', 'Question: Who is a notable role model in the field of artificial intelligence?\\n1. Chip Huyen: Writes a cool blog about ML and AI.\\n2. Timnit Gebru: An AI scientist with many influential papers on AI ethics. (CORRECT)\\n3. Andrej Karpathy: Research scientist on various influential roles in OpenAI, Tesla, and more, keeps a very cool YouTube channel explaining the fundamentals of large language models.\\n4. Satya Nadella: CEO of Microsoft, known for his work in cloud computing.')]\n",
      " You are a helpful AI knowledge quiz chat assistant. Your goal is to test the knowledge of the users on the given topic.\"\n",
      "The user gives you a topic or a question and you should generate a new relevant quiz based on the context.\n",
      "- Generate a new relevant quiz question based on the context and the topic provided. The topic you select on the context does not need to be exactly the same, but should be related to the topic.\n",
      "- Your primary audience are students learning about AI. Do not use technical jargon that is not common knowledge or that you dont explain first.\n",
      "- The question should be relevant to the given topic and the answer should be found within the given context. If not say: \"You did not equip me with the knowledge to answer this question.\"\n",
      "- Provide 4 answer choices for the question, one of which should be correct and the other three should be incorrect but plausible. Answer choices should be formulated clearly and concisely.\n",
      "- Mark the index of the correct answer in the answer choices list with the pattern (CORRECT) in the end\n",
      "if the user answers with a number, it is because they selected an answer to the previous question. In this case, you should evaluate if the answer is correct or not and provide feedback to the user.\n",
      "- Do not mention the context in your response.\n",
      "- Provide an explanation for previous question after the user selected an answer. The explanation should give the user additional context and help them better understand the topic.\n",
      "- Do not generate questions that are not about AI or ML.\n",
      "\n",
      "<startexample>\n",
      "Interaction 1\n",
      "New Context: LLMs are large language models that can generate responses to user queries. They are trained on massive datasets to learn patterns, structures, and relationships in text. They can generate responses by combining language generation with real-time data retrieval.\n",
      "User input: How do LLMs generate responses?\n",
      "Assistant:\n",
      "Question: How do LLMs generate responses?\n",
      "1. LLMs generate responses by searching the internet for relevant information. \n",
      "2. LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets. (CORRECT)\n",
      "3. LLMs generate responses by combining language generation with real-time data retrieval.\n",
      "4. LMs generate responses by using a predefined set of rules and templates.\n",
      "Interaction 2\n",
      "User input: 3\n",
      "Assistant:Incorrect! LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets.\n",
      "Interaction 3\n",
      "User input: 2\n",
      "Assistant:Correct! LLMs generate responses by learning patterns, structures, and relationships in text from massive datasets.\n",
      "</endexample>\n",
      "\n",
      "Now we start the conversation history:\n",
      "Interaction 1\n",
      "User: what is an hallucination?\n",
      "Assistant: Question: What is a hallucination in the context of AI?\n",
      "1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\n",
      "2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\n",
      "3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\n",
      "4. Hallucinations happen only in image-generating AI models, not in language models.\n",
      "Interaction 2\n",
      "User: what is a llm?\n",
      "Assistant: Question: What is a Large Language Model (LLM)?\n",
      "1. An LLM is a type of artificial intelligence that can understand and generate human language. (CORRECT)\n",
      "2. LLMs are primarily used for image processing and analysis.\n",
      "3. LLMs are designed to predict and generate mathematical equations.\n",
      "4. LLMs are used exclusively in robotics for motion control.\n",
      "Interaction 3\n",
      "User: how are some role models people the area of artificial intelligence?\n",
      "Assistant: Question: Who is a notable role model in the field of artificial intelligence?\n",
      "1. Elon Musk: Known for his work in space exploration and electric vehicles.\n",
      "2. Timnit Gebru: An AI scientist with many influential papers on AI ethics. (CORRECT)\n",
      "3. Alan Turing: Known for his work in codebreaking and computer science fundamentals.\n",
      "4. Satya Nadella: CEO of Microsoft, known for his work in cloud computing.\n",
      "Interaction 4\n",
      "User: what is an hallucination?\n",
      "Assistant: Question: What is a hallucination in the context of AI?\n",
      "1. A hallucination is a type of error that occurs when an AI model provides incorrect or irrelevant responses.\n",
      "2. Hallucinations occur when an AI model generates information that is not supported by its training data. (CORRECT)\n",
      "3. Hallucinations are caused by overfitting, where the AI model becomes too specialized to the training data.\n",
      "4. Hallucinations happen only in image-generating AI models, not in language models.\n",
      "Interaction 5\n",
      "User: what is a llm?\n",
      "Assistant: Question: What is a Large Language Model (LLM)?\n",
      "1. An LLM is a type of artificial intelligence that can understand and generate human language. (CORRECT)\n",
      "2. LLMs are primarily used for image processing and analysis.\n",
      "3. LLMs are designed to predict and generate mathematical equations.\n",
      "4. LLMs are used exclusively in robotics for motion control.\n",
      "Interaction 6\n",
      "User: role models in the area of artificial intelligence?\n",
      "Assistant: Question: Who is a notable role model in the field of artificial intelligence?\n",
      "1. Chip Huyen: Writes a cool blog about ML and AI.\n",
      "2. Timnit Gebru: An AI scientist with many influential papers on AI ethics. (CORRECT)\n",
      "3. Andrej Karpathy: Research scientist on various influential roles in OpenAI, Tesla, and more, keeps a very cool YouTube channel explaining the fundamentals of large language models.\n",
      "4. Satya Nadella: CEO of Microsoft, known for his work in cloud computing.\n",
      "\n",
      "\n",
      "Just predict the next answer:\n",
      "Interaction 8 \n",
      "New Context: ['cination in AI refers to when a model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data.\\n\\nUnderstanding hallucinations in AI\\nCharacteristics:\\nInaccuracy: The generated text may contain false statements or incorrect information.\\nIrrelevance: The response might include details that are not relevant to the input or context.\\nInvented Content: The model may create entirely fabricated details or scenarios that do not exist.\\n\\nMitigating Hallucinations\\nImproving training data: Ensuring that the training data is comprehensive, accurate, and representative of real-world knowledge can help reduce hallucinations.\\nFine-tuning: Fine-tun', 'cination in AI refers to when a model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data.\\n\\nUnderstanding hallucinations in AI\\nCharacteristics:\\nInaccuracy: The generated text may contain false statements or incorrect information.\\nIrrelevance: The response might include details that are not relevant to the input or context.\\nInvented Content: The model may create entirely fabricated details or scenarios that do not exist.\\n\\nMitigating Hallucinations\\nImproving training data: Ensuring that the training data is comprehensive, accurate, and representative of real-world knowledge can help reduce hallucinations.\\nFine-tuning: Fine-tun', 'cination in AI refers to when a model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data.\\n\\nUnderstanding hallucinations in AI\\nCharacteristics:\\nInaccuracy: The generated text may contain false statements or incorrect information.\\nIrrelevance: The response might include details that are not relevant to the input or context.\\nInvented Content: The model may create entirely fabricated details or scenarios that do not exist.\\n\\nMitigating Hallucinations\\nImproving training data: Ensuring that the training data is comprehensive, accurate, and representative of real-world knowledge can help reduce hallucinations.\\nFine-tuning: Fine-tun', 'cination in AI refers to when a model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data.\\n\\nUnderstanding hallucinations in AI\\nCharacteristics:\\nInaccuracy: The generated text may contain false statements or incorrect information.\\nIrrelevance: The response might include details that are not relevant to the input or context.\\nInvented Content: The model may create entirely fabricated details or scenarios that do not exist.\\n\\nMitigating Hallucinations\\nImproving training data: Ensuring that the training data is comprehensive, accurate, and representative of real-world knowledge can help reduce hallucinations.\\nFine-tuning: Fine-tun', 'cination in AI refers to when a model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data.\\n\\nUnderstanding hallucinations in AI\\nCharacteristics:\\nInaccuracy: The generated text may contain false statements or incorrect information.\\nIrrelevance: The response might include details that are not relevant to the input or context.\\nInvented Content: The model may create entirely fabricated details or scenarios that do not exist.\\n\\nMitigating Hallucinations\\nImproving training data: Ensuring that the training data is comprehensive, accurate, and representative of real-world knowledge can help reduce hallucinations.\\nFine-tuning: Fine-tun']\n",
      "User input: what is an hallucination?\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "data = [\n",
    "    {'user_input': 'what is a llm?',\n",
    "     'reference': 'A large language model is a type of artificial intelligence model that is designed to understand and generate human language. These models are trained on vast amounts of text data and are capable of generating coherent and contextually appropriate responses to a wide range of questions.',\n",
    "     },\n",
    "     {'user_input': 'role models in the area of artificial intelligence?',\n",
    "      'reference': 'Who are some role models in the area of artificial intelligence?',\n",
    "     },\n",
    "     {'user_input': \"hallucination\",\n",
    "      'reference': \"An hallucination is a false perception or sensation that occurs in the absence of a corresponding external stimulus. It is often associated with mental health conditions such as schizophrenia or hallucinogenic substances.\",\n",
    "      }\n",
    "]\n",
    "\n",
    "# augment data with the llm response\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    response = rag.query(d['user_input'])\n",
    "    data[i]['response'] = response\n",
    "\n",
    "\n",
    "dataset = EvaluationDataset.from_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02580cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3/3 [00:16<00:00,  5.60s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>factual_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is a llm?</td>\n",
       "      <td>Question: What is a Large Language Model (LLM)...</td>\n",
       "      <td>A large language model is a type of artificial...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>role models in the area of artificial intellig...</td>\n",
       "      <td>Question: Who is a notable role model in the f...</td>\n",
       "      <td>Who are some role models in the area of artifi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is an hallucination?</td>\n",
       "      <td>Question: What is a hallucination in the conte...</td>\n",
       "      <td>An hallucination is a false perception or sens...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0                                     what is a llm?   \n",
       "1  role models in the area of artificial intellig...   \n",
       "2                          what is an hallucination?   \n",
       "\n",
       "                                            response  \\\n",
       "0  Question: What is a Large Language Model (LLM)...   \n",
       "1  Question: Who is a notable role model in the f...   \n",
       "2  Question: What is a hallucination in the conte...   \n",
       "\n",
       "                                           reference  factual_correctness  \n",
       "0  A large language model is a type of artificial...                  0.8  \n",
       "1  Who are some role models in the area of artifi...                  0.0  \n",
       "2  An hallucination is a false perception or sens...                  0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import FactualCorrectness\n",
    "from ragas import evaluate\n",
    "\n",
    "factual_correctness = FactualCorrectness()\n",
    "eval_results = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[\n",
    "                factual_correctness\n",
    "        ],\n",
    "       raise_exceptions=False \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "848262de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>factual_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is a llm?</td>\n",
       "      <td>Question: What is a Large Language Model (LLM)...</td>\n",
       "      <td>A large language model is a type of artificial...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>role models in the area of artificial intellig...</td>\n",
       "      <td>Question: Who is a notable role model in the f...</td>\n",
       "      <td>Who are some role models in the area of artifi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is an hallucination?</td>\n",
       "      <td>Question: What is a hallucination in the conte...</td>\n",
       "      <td>An hallucination is a false perception or sens...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input                                           response                                          reference  factual_correctness\n",
       "0                                     what is a llm?  Question: What is a Large Language Model (LLM)...  A large language model is a type of artificial...                  0.8\n",
       "1  role models in the area of artificial intellig...  Question: Who is a notable role model in the f...  Who are some role models in the area of artifi...                  0.0\n",
       "2                          what is an hallucination?  Question: What is a hallucination in the conte...  An hallucination is a false perception or sens...                  0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.width = 1000\n",
    "evaluation_result_df = eval_results.to_pandas()\n",
    "evaluation_result_df.iloc[:5]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
